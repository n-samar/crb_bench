\section{BitPacker Representation}
\vspace{-0.05in}
\subsection{Overview}
\label{sec:overview}

\name is an implementation of CKKS that leverages RNS representation more
effectively than RNS-CKKS by keeping most data packed in narrow words of a
fixed size.

% dsm: Note that the paragraphs in this overview are written to follow a
% completely parallel structure to Sec 2.3, down to the paragraph names when
% possible!

\figLevelsBitPacker

\paragraph{\name decouples residues and scales:}
\autoref{fig:levels} shows an example of \name's representation, showing how
residues and scales evolve across levels.
This example mimics the RNS-CKKS example in \autoref{fig:levelsRnsCkks}
to facilitate a side-by-size comparison: in both cases, the ciphertext has a
240-bit $Q$ at $L=6$, uses a 40-bit scale at each level, and hardware has
64-bit words.
Whereas RNS-CKKS represents this ciphertext using 6 40-bit residues, one
per level (\autoref{fig:levelsRnsCkks}), \name represents this ciphertext using
only 4 residues: the first 3 residues use moduli $q_0$, $q_1$, and $q_2$ close
to the hardware word size, 64 bits, and the fourth residue uses modulus $q_3$,
which has 48 bits.
Together, these residues still encode a 240-bit integer, though with a
\emph{different decomposition}.
Using 4 residues instead of 6 yields big savings, because homomorphic operations 
have superlinear cost with the number of residues (\autoref{sec:implementation}).
%Thus, this 1.5$\times$ space reduction translates to a 1.9$\times$ reduction
%in energy, 
%as we will see in \autoref{sec:implementation}.

\paragraph{Terminal and non-terminal residues:}
In general, a \name ciphertext consists of \emph{(1)} several word-sized
residues (like $q_0$, $q_1$, and $q_2$ above), which we call
\green{non-terminal residues}, shown in green in \autoref{fig:levels};
and \emph{(2)} one or a small number of residues smaller than the word size
(like $q_3$ above), which we call \blue{terminal residues}, shown in blue in
\autoref{fig:levels}.
Terminal residues allow \name to represent coefficients with an arbitrary
number of bits.

All examples in \autoref{fig:levelsRnsCkks} show a single terminal residue, 
but as we will see later, due to restrictions on residue moduli, it
is sometimes necessary to use more than one terminal modulus (typically, no
more than two terminal moduli are needed).

% dsm: This figure has a big problem, this representation for L=5 would require
% an 8-bit modulus!!! If this is possible for small N (small. enought that it'd
% cover this bitwidth), then maybe we could leave it and use this as an example
% to talk about the need for multiple terminal moduli.
% nikola: this is not a problem

\paragraph{Rescale and mod-down:}
\name's representation requires new techniques for rescaling and modding-down,
and our key contribution is to show that these modulus changes are possible and
simple.
The lack of these mechanisms is what led RNS-CKKS to link residues and
scales~\cite{cheon2019full}.

For example, in \autoref{fig:levels}, rescaling the $L=6$ ciphertext after a
multiplication to produce an $L=5$ ciphertext results in coefficients that
still use 4 residues: the 3 non-terminal residues still use the same moduli
($q_0$, $q_1$, and $q_2$), but the terminal residue uses a \emph{smaller}
terminal modulus, $q_3'$ ($\neq q_3$).
Similarly, an $L=4$ uses three residues, with non-terminal moduli $q_0$ and
$q_1$, and terminal residue $q_2'$.

This example shows that, whereas RNS-CKKS only sheds residue moduli, \name
\emph{introduces new ones} as it moves across levels.
Our key insight is that this can be done accurately by temporarily scaling
\emph{up} the ciphertext to use a larger $Q$ and number of residues, then
shedding the unneeded ones.

\name's rescale and mod-down procedures
%are more expensive than RNS-CKKS's, but still % dsm: Not really, per evaluation...
take a small fraction of time and energy (\OK{4-7\%} in our evaluation),
and yield large efficiency gains in return.

\smallskip

In the rest of this section, we first explain how \name's rescale and mod-down
operations work (\autoref{sec:levelMgmt}).
Because \name is a simple change in RNS representation, we only explain rescale
and mod-down, as \emph{all other operations are exactly the same as in
RNS-CKKS}.
Then, we describe how \name chooses terminal and non-terminal moduli to achieve
high efficiency and accuracy (\autoref{sec:modulusChain}).
Finally, we conclude with a security discussion, showing that \name, by being a
change in representation, achieves the same security level as CKKS and CKKS-RNS
(\autoref{sec:security}).

\subsection{Level Management}
\label{sec:levelMgmt}

\figBpRescale

Rescale and mod-down move a ciphertext from a higher source level $L_{src}$ to
a lower destination level $L_{dst}$.
Unlike in RNS-CKKS, in \name, the ciphertext at $L_{dst}$ does not use a subset
of the residue moduli at $L_{src}$: its terminal moduli are different.
Thus, new level management operations---rescale and mod-down---are needed
to make \name possible.
%As mentioned, all other operations are identical in \name and RNS-CKKS.

% nikola: some sign-posting
We now present \texttt{bpRescale} and \texttt{bpModDown},
the \name versions of rescale and mod-down.
These procedures make use of two low-level RNS operations: \emph{scale-up} and
\emph{scale-down}, which we also explain.

Rescale and mod-down both follow the same process to change terminal
moduli.
\autoref{fig:bpRescale} shows this process for rescale, when moving a
ciphertext from $L_{src}=5$ to $L_{dst}=4$.
(Because rescaling happens after a multiplication, the initial scale of the
ciphertext is $S_5^2$.)
First, the ciphertext is \emph{scaled up} to use a larger modulus, introducing
the terminal residue moduli of $L_{dst}$.
Then, the ciphertext is \emph{scaled down} to shed the moduli at $L_{src}$ that
are not present in  $L_{dst}$.
This always eliminates $L_{src}$'s terminal moduli, and may shed some
non-terminal moduli as well.
In \autoref{fig:bpRescale}'s example, rescaling first adds a new residue with
terminal modulus $q_2'$, then sheds $q_3'$ and $q_2$.

\input{listings/scale_up.tex}

\paragraph{Scale-up:} To implement the first step above, we
leverage a procedure called \emph{scale-up}.
A scale-up of a ciphertext with modulus $Q$, scale $S$, and noise $\delta$ by a
factor $d$ coprime with $Q$ produces a ciphertext that encrypts the same data
as the input with modulus $Qd$, scale $Sd$, and noise $\delta d$.

\autoref{lst:scaleUp} shows the implementation of the \texttt{scaleUp}
procedure for an RNS representation.
\texttt{scaleUp} is not our contribution: RNS-CKKS uses \texttt{scaleUp} prior
to bootstrapping, to produce a much larger ciphertext that bootstrapping can
denoise, as \autoref{fig:sawtooth} showed.
Our insight is that scale-ups can also be used to implement rescale and
mod-down.

\input{listings/bp_rescale.tex}
\input{listings/scale_down.tex} % babysitted

\paragraph{Rescale:}
\autoref{lst:bpRescale} shows the implementation of \name's rescale,
\texttt{bpRescale}.
\texttt{bpRescale} reduces the ciphertext's level by one, i.e., from $L$
to $L-1$.
First, \texttt{bpRescale} scales-up the ciphertext by all the residue moduli at
$L-1$ that do not appear at $L$ (lines \OK{3--5}).
Then, \texttt{bpRescale} scales-down this intermediate ciphertext by all the
residue moduli that appear at $L$ but not at $L-1$ (lines \OK{6--8}), shedding
these moduli and producing the final result.

\texttt{bpRescale} implements the scale-down by calling the \texttt{scaleDown}
procedure.
\autoref{lst:scaleDown} shows our implementation of \texttt{scaleDown}.
This procedure rescales an integer $x$ by multiple residue moduli
${p_{0},p_{1},...,p_{k-1}}$, reducing the scale (and noise) by a factor
$P = p_{0} \cdot p_{1} \cdot ... \cdot p_{k-1}$ and shedding these moduli.
This is done by computing the floor of
$x/{p_{0}p_{1}\cdot...\cdot p_{k-1}}$.
\autoref{lst:scaleDown} shows how this is done efficiently in RNS.
To simplify the code, line \OK{5} reorders $x$'s residues, placing the
residues to be shed at the end.

\texttt{scaleDown} uses two types of precomputed values.
\texttt{C[i][j]} are the product of $q_i$ and
the B\'ezout coefficient corresponding to $q_i$ for $(q_i, P/q_i)$ modulo
$q_j$~\cite{bajard2017full};
thus, each \text{C[i][j]} fits into one hardware word.
\texttt{InvP} is the multiplicative inverse of $P$ modulo $Q/P$, where $Q$ is
the product of the $R$ residue moduli of the input
\texttt{ct}~\cite{bajard2017full}.
Thus, \texttt{InvP} can be represented in RNS with $R-k$ hardware words.

\texttt{scaleDown} is the dual of \texttt{scaleUp}, and is similar to calling
\texttt{rnsCkksRescale} (\autoref{lst:rnsCkksRescale}) multiple times, since
\texttt{rns\-Ckks\-Rescale} scales down by one residue modulus at a time.
% nikola: it used to say here that shedding multiple moduli at once is more
% accurate. This is true so little that it doesn't matter
However, shedding multiple moduli at once better leverages existing
accelerators, as we will see in \autoref{sec:implementation}.

\figBpModDown

\input{listings/bp_mod_down.tex}

\paragraph{Mod-down:}
\autoref{lst:bpModDown} shows the implementation of \name's mod-down,
\texttt{bpModDown}. \autoref{fig:bpModDown} shows \texttt{bpModDown}'s
behavior, illustrating how residues and scales evolve over time (similarly to how
\autoref{fig:bpRescale} illustrates \texttt{bpRescale}).

\texttt{bpModDown} works similarly to \texttt{rnsCkksModDown}: it performs a scale
adjustment (line \OK{3--4}) and a rescale (line \OK{5}), except: \emph{(1)} the
scale is adjusted by $K = (Q_L/Q_{L-1}) \ast (S_{L-1}/S_L)$ instead of $K =
q_{L-1} \ast (S_{L-1}/S_L)$; this is because \name moduli, and thus scales,
change differently across levels than in RNS-CKKS (compare scales in
\autoref{fig:levels} and \autoref{fig:levelsRnsCkks});
and \emph{(2)} we use \texttt{bpRescale} instead of \texttt{rnsCkksRescale},
again, to match moduli and scales with those produced by
\texttt{bpRescale}.

\name must also support modding down by multiple levels.
This follows the same approach as RNS-CKKS mod-downs: we first drop residue
moduli as long as the modulus is larger than $L_{dst}+1$'s modulus;
we then apply the same algorithm as in
\autoref{lst:bpModDown}.
% dsm: This was saying bpModDown does this, but bpModDown does not do that...

\subsection{Choosing Residue Moduli}\label{sec:modulusChain}

Choosing residue moduli in \name is more involved than in RNS-CKKS.
\autoref{fig:constraints}
summarizes the requirements that \name must meet when choosing moduli.
Each FHE program requires a number of \emph{levels}, each with a \emph{target
scale}.
At level 0, ciphertexts must have a particular modulus width $\log_2 Q_{min}$
to enable bootstrapping or decryption; the program also imposes a maximum
modulus width, $\log_2 Q_{max}$, needed for security (\autoref{sec:security}).
The program also fixes $N$, the size of each ciphertext polynomial.
Hardware fixes the word size, $w$.

These constraints limit the moduli that \name can use.
First, residue moduli must be primes $\leq w$ bits wide, so that each residue
fits in a single hardware word.
Second, moduli must be \emph{NTT-friendly primes}~\cite{lyubashevsky2013ideal},
i.e., prime numbers that give remainder $1$ when divided by $2N$.

Unfortunately, few primes are NTT-friendly.
For instance, with $N=64K$ and $w=28$ bits, there are only 244 NTT-friendly
primes ($w=32$ bits increases this to 3,126 primes).
Moreover, all NTT-friendly primes are larger than $2N$,
which places a harsh
lower bound on moduli size.
For example, with $N=64K$, all NTT-friendly primes are 17 bits
or wider.

\figConstraints

These restrictions make it necessary to sometimes use multiple terminal moduli.
For example, with $w=28$ bits, a 70-bit coefficient needs three residues.
But if we were to use two 28-bit non-terminal residues, the terminal residue
would need a 14-bit modulus, which does not exist.
Instead, this can be achieved with, for example, one 28-bit non-terminal
residue and two 24-bit terminal residues, for which valid moduli exist (but
other combinations are possible).

\smallskip

\paragraph{Choosing target moduli:}
To generate  a modulus for level $L$, we first set its target modulus.
The target modulus at level $L$ can be derived from the actual scale ($S_{L+1}$) and
modulus ($Q_{L+1}$) at level $L+1$, as well as the target scale at level
$L$~\cite{kim2022approximate}.
Because of this dependence, we define the mapping between levels and moduli
starting from the top level and going down.

\autoref{lst:greedy} shows our algorithm to select residue moduli for a particular level.
We detail its operation below.

\paragraph{Non-terminal moduli:}
Our modulus selection algorithm first chooses non-terminal moduli that keep the
ciphertext as packed as possible. This is simple: with a $w$-bit word size, the
algorithm chooses the NTT-friendly primes closest to $2^w$ and smaller than
$2^w$.
The algorithm picks enough non-terminal moduli $q_0, ..., q_k$ to cover the
largest ciphertext needed (i.e., $k$ is such that $q_0 \cdot ... \cdot q_k >
Q_{max}$).
The algorithm also maintains $q_0 > ... > q_k$, so that lower-indexed
non-terminal moduli are larger (as they are used by more levels).

\paragraph{Terminal moduli:}
Next, the modulus selection algorithm picks the terminal moduli associated with
each level.
To do this, it tries to minimize the distance between the level's target scale
(requested by the program) and the actual scale.
We use a simple greedy implementation, shown in \autoref{lst:greedy}.
The algorithm computes the target $Q_L$ for each level, and tries to match it
using the smallest number of terminal primes.
For instance, in the above example for a 70-bit prime, this algorithm will
first try a single terminal prime, find that there is no single 4-bit prime,
and then move on to explore combinations of two terminal primes.

\input{listings/greedy.tex}

In principle, using a larger number of non-terminal primes may enable finding a
more precise match to the target scale, but we must also avoid using a large
number of terminal primes, as doing so makes level management more expensive.
Thus, we accept solutions that are within 0.5 bits of the target scale (i.e.,
$|\log_2 S_L - \log_2 T_L| < 0.5$).
We find that this works well in practice and does not impact accuracy.

% nikola: O(.) of this algo is terrible, so deleted that.
\paragraph{Performance:}
This algorithm completes in less than a second for all word sizes we evaluate
(\autoref{sec:evaluation})
We use precomputed NTT-friendly primes; for $w \leq 36$ bits, we exhaustively
enumerate all such primes; for larger word sizes, we exhaustively enumerate
enough primes near $2^w$ to always use the best non-terminal primes, and sample
500 primes evenly spaced out logarithmically, to be used as candidates for terminal primes.


\subsection{Security}
\label{sec:security}

\name does not change the security of CKKS compared to RNS-CKKS, or to the
original (non-RNS) CKKS implementation~\cite{cheon:asiacrypt17:ckks}.
CKKS depends on the security of the ring learning with errors (R-LWE)
problem~\cite{brakerski2011fully}.
The security of a CKKS ciphertext is proportional to $N / \log_2Q$, i.e., using
larger ciphertext polynomials increases security, and using wider coefficients
decreases it.

\name, RNS-CKKS, and CKKS use the same $N$, and all are guaranteed to keep
every ciphertext modulus $Q$ smaller than $Q_{max}$, as defined by the program
constraints.
The exact moduli used by \name, RNS-CKKS, and CKKS are different (since they
use different representations), but the only relevant aspect for security is
that they do not exceed $Q_{max}$.

Security in R-LWE also depends on several other parameters, such as the sparsity
of the secret key or the distribution of noise injected at encryption
time~\cite{albrecht2018estimate}, but all these aspects are independent of how
ciphertexts are represented.
This means that \name achieves the same level of security as other CKKS
implementations.

